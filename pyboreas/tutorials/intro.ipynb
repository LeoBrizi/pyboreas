{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3812016",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Before starting this tutorial, you'll need to have at least one sequence from the Boreas dataset downloaded.\n",
    "If you're working on a local machine, follow these steps to download a sequence:\n",
    "1. [Create an AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/)\n",
    "2. [Install the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)\n",
    "3. Create a `root` folder to store the dataset, example: `/path/to/data/boreas/` Each sequence will then be a folder under `root`.\n",
    "4. Use the AWS CLI to download a sequence:\n",
    "```\n",
    "root=/path/to/data/boreas/\n",
    "sequence=boreas-2021-09-02-11-42\n",
    "aws s3 sync s3://boreas/$sequence $root$sequence\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from pyboreas import BoreasDataset\n",
    "from pyboreas.utils.utils import get_inverse_tf\n",
    "\n",
    "root = '/path/to/data/boreas/'\n",
    "split = None\n",
    "# AWS: Note: Free Tier SageMaker instances don't have enough storage (25 GB) for 1 sequence (100 GB)\n",
    "# root = '/home/ec2-user/SageMaker/boreas/'\n",
    "# split = [['boreas-2021-09-02-11-42', 163059759e6, 163059760e6-1]]\n",
    "\n",
    "# With verbose=True, the following will print information about each sequence\n",
    "bd = BoreasDataset(root, split=split, verbose=True)\n",
    "# Grab the first sequence\n",
    "seq = bd.sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc025aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each sequence has it's own calibration:\n",
    "seq.calib.print_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51943e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Let's visualize a lidar frame:\n",
    "lid = seq.get_lidar(0)\n",
    "lid.visualize(figsize=(10, 10), color='intensity', vmin=5, vmax=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's visualize the first camera frame:\n",
    "cam = seq.get_camera(0)\n",
    "cam.visualize(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049aca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's visualize the first radar frame:\n",
    "rad = seq.get_radar(0)\n",
    "rad.visualize(cart_resolution=0.25, cart_pixel_width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b675d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that each sensor frame has a timestamp, pose (4x4 homogeneous transform), and velocity information.\n",
    "lid = seq.get_lidar(0)\n",
    "print('Lidar:')\n",
    "print('timestamp: {}'.format(lid.timestamp))\n",
    "print('pose (T_enu_lidar):')\n",
    "print(lid.pose)\n",
    "print('velocity (wrt ENU):')\n",
    "print(lid.velocity)\n",
    "print('body rate (wrt sensor):')\n",
    "print(lid.body_rate)\n",
    "\n",
    "# Note that lidar and camera frames are collected at 10Hz, but radar frames collected at 4 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform data from one frame to another, use the poses\n",
    "index = 0\n",
    "lid = seq.get_lidar(index)\n",
    "p_lid = np.array([1, 0, 0, 1]).reshape(4, 1)\n",
    "print('point in lidar frame')\n",
    "print(p_lid)\n",
    "print('lidar pose (T_enu_lidar) at time: {}'.format(lid.timestamp))\n",
    "T_enu_lidar = lid.pose\n",
    "print(T_enu_lidar)\n",
    "\n",
    "# **Important: camera, lidar, radar measurements are NOT synchronous\n",
    "# camera frame X does not necessarily correspond to lidar frame X\n",
    "# They may be close, but will have been collected at different times, see below:\n",
    "cam = seq.get_camera(index)\n",
    "print('camera pose (T_enu_camera) at time: {}'.format(cam.timestamp))\n",
    "T_enu_camera = cam.pose\n",
    "print(T_enu_camera)\n",
    "\n",
    "T_camera_lidar = np.matmul(get_inverse_tf(T_enu_camera), T_enu_lidar)\n",
    "print('T_camera_lidar:')\n",
    "print(T_camera_lidar)\n",
    "print('distance: {}'.format(np.linalg.norm(T_camera_lidar[:3, 3])))\n",
    "\n",
    "print('point in camera frame:')\n",
    "p_cam = np.matmul(T_camera_lidar, p_lid)\n",
    "print(p_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: using an iterator\n",
    "cam_iter = bd.sequences[0].get_camera_iter()\n",
    "cam0 = next(cam_iter)  # First camera frame\n",
    "cam1 = next(cam_iter)  # Second camera frame\n",
    "print(cam0.timestamp)\n",
    "print(cam1.timestamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
