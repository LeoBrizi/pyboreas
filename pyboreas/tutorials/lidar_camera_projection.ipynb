{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aef88f3",
   "metadata": {},
   "source": [
    "# Lidar to Camera Projection\n",
    "\n",
    "Before starting this tutorial, you'll need to have at least one sequence from the Boreas dataset downloaded.\n",
    "If you're working on a local machine, follow these steps to download a sequence:\n",
    "1. [Create an AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/)\n",
    "2. [Install the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)\n",
    "3. Create a `root` folder to store the dataset, example: `/path/to/data/boreas/` Each sequence will then be a folder under `root`.\n",
    "4. Use the AWS CLI to download a sequence:\n",
    "```\n",
    "root=/path/to/data/boreas/\n",
    "sequence=boreas-2021-09-02-11-42\n",
    "aws s3 sync s3://boreas/$sequence $root$sequence\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyboreas import BoreasDataset\n",
    "from pyboreas.utils.utils import get_inverse_tf\n",
    "\n",
    "root = '/path/to/data/boreas/'\n",
    "split = None\n",
    "# AWS: Note: Free Tier SageMaker instances don't have enough storage (25 GB) for 1 sequence (100 GB)\n",
    "# root = '/home/ec2-user/SageMaker/boreas/'\n",
    "# split = [['boreas-2021-09-02-11-42', 163059759e6, 163059760e6-1]]\n",
    "\n",
    "bd = BoreasDataset(root, split=split, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b645e",
   "metadata": {},
   "source": [
    "## Removing Motion Distortion\n",
    "`body_rate` is the velocity of the sensor in the sensor frame, $\\boldsymbol{\\varpi}$\n",
    "\n",
    "$\\Delta t = t - t_{\\text{ref}}$ is the time difference between a given measurement time `t` and a reference time, `tref`.\n",
    "\n",
    "$$\n",
    "\\mathbf{T}_{\\text{undistort}} = \\exp(\\Delta t \\boldsymbol{\\varpi}^\\wedge)\n",
    "$$\n",
    "\n",
    "Convenience function: `PointCloud.remove_motion()`\n",
    "\n",
    "## Transform from Lidar to Camera\n",
    "$$\n",
    "\\mathbf{x}_{c} = \\mathbf{T}_{\\text{enu_camera}}^{-1} \\mathbf{T}_{\\text{enu_lidar}} \\mathbf{x}_{l}\n",
    "$$\n",
    "\n",
    "Convenience function: `PointCloud.transform()`\n",
    "\n",
    "## Project onto Image Plane\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\end{bmatrix} = \\mathbf{D}~\\mathbf{P}~\\frac{1}{z}~\\mathbf{x}_c\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where} ~~ \\mathbf{D} = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{bmatrix}, ~ \\mathbf{P} = \\begin{bmatrix} f_u & 0 & c_u & 0 \\\\ 0 & f_v & c_v & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Convenience function: `PointCloud.project_onto_image()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37aabc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "seq = bd.sequences[0]\n",
    "seq.synchronize_frames(ref='camera')  # simulates having synchronous measurements\n",
    "idx = 0  # try different frame indices!\n",
    "cam = seq.get_camera(idx)\n",
    "lid = seq.get_lidar(idx)\n",
    "\n",
    "# Remove motion distortion from pointcloud:\n",
    "print('body rate in lidar frame:')\n",
    "print(lid.body_rate)\n",
    "lid.remove_motion(lid.body_rate)\n",
    "\n",
    "# Get the transform from lidar to camera:\n",
    "T_enu_camera = cam.pose\n",
    "T_enu_lidar = lid.pose\n",
    "T_camera_lidar = np.matmul(get_inverse_tf(T_enu_camera), T_enu_lidar)\n",
    "print('T_camera_lidar:')\n",
    "print(T_camera_lidar)\n",
    "lid.transform(T_camera_lidar)\n",
    "\n",
    "# Remove points outside our region of interest\n",
    "lid.passthrough([-75, 75, -20, 10, 0, 40])  # xmin, xmax, ymin, ymax, zmin, zmax\n",
    "\n",
    "# Project lidar points onto the camera image, using the projection matrix, P0.\n",
    "uv, colors = lid.project_onto_image(seq.calib.P0)\n",
    "\n",
    "# Draw the projection\n",
    "fig = plt.figure(figsize=(24.48, 20.48), dpi=100)\n",
    "ax = fig.add_subplot()\n",
    "ax.imshow(cam.img[:, :, ::-1])\n",
    "ax.set_xlim(0, 2448)\n",
    "ax.set_ylim(2048, 0)\n",
    "ax.scatter(uv[:, 0], uv[:, 1], c=colors, marker=',', s=3, edgecolors='none', alpha=0.7, cmap='jet')\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
